{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualization \n",
    "\n",
    "In this notebook I use Neural Networks to identify underlying patterns in our book data that our stakeholders can use to impact their businesses.\n",
    "\n",
    "\n",
    "By: Prince Okpoziakpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2761, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the book data into the 'books_df' dataframe\n",
    "books_df = pd.read_csv('../data/isbn13_results.csv').drop(columns=['Unnamed: 0'])\n",
    "books_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2620, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the books that have a description\n",
    "books_df = books_df.loc[~books_df.description.isna()] \n",
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2581, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the books that have categories\n",
    "books_df = books_df.loc[~books_df.main_categories.isna()]\n",
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comedy programs']                         1\n",
       "['Alternative comic books, strips, etc']    1\n",
       "['Candy']                                   1\n",
       "['Cinematography']                          1\n",
       "['Popular music']                           1\n",
       "                                           ..\n",
       "['Data structures (Computer science)']      1\n",
       "['Counterculture']                          1\n",
       "['Computer engineers']                      1\n",
       "['Presidents']                              1\n",
       "['Coma']                                    1\n",
       "Name: categories, Length: 406, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = books_df.categories.value_counts()\n",
    "category_counts[category_counts == 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize each document from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the vectorizer and transforming the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 23128\n",
      "Sample features: ['altar' 'alter' 'alteration' 'altered' 'altering']\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# instantiate the CountVectorizer object; `stop_words` parameter makes sure \n",
    "# we exclude English stop words\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# extract the 'description' column and convert it into an array \n",
    "descriptions = books_df.description.to_numpy()\n",
    "\n",
    "# fit the vectorizer and transform the corpus\n",
    "bag_of_words = vectorizer.fit_transform(descriptions)\n",
    "\n",
    "print(f\"Vocabulary size: {vectorizer.vocabulary_.__len__()}\")\n",
    "print(f\"Sample features: {vectorizer.get_feature_names_out()[1000:1005]}\\n\")\n",
    "print(bag_of_words.toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the categories of each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories:  559\n"
     ]
    }
   ],
   "source": [
    "# determine the number of unique categories that exist in the dataset\n",
    "all_categories = [] \n",
    "for categories_list_string in books_df.main_categories: \n",
    "    if type(categories_list_string) == str:\n",
    "        c = categories_list_string.\\\n",
    "        rstrip().\\\n",
    "        lstrip().\\\n",
    "        replace('[', '').\\\n",
    "        replace(']', '').\\\n",
    "        replace(\"\\'\", '').\\\n",
    "        replace(\"\\\"\", '').\\\n",
    "        split(',')\n",
    "        all_categories += c\n",
    "\n",
    "print(\"Number of unique categories: \", len(set(all_categories)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and transform the targets into a label indicator matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Juvenile Fiction']), list(['Juvenile Fiction']),\n",
       "       list(['Fiction']), ..., list(['Business & Economics']),\n",
       "       list(['Drama']), list(['Fiction'])], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the type of the categories from string into an array of categories\n",
    "all_categories = books_df.main_categories.apply(\n",
    "    lambda s: s.\\\n",
    "        rstrip().\\\n",
    "        lstrip().\\\n",
    "        replace('[', '').\\\n",
    "        replace(']', '').\\\n",
    "        replace(\"\\'\", '').\\\n",
    "        replace(\"\\\"\", '').\\\n",
    "        split(',')\n",
    ")\n",
    "all_categories.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2581, 559)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the binarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# fit and transform the labels of the targets into a label indicator matrix\n",
    "targets = mlb.fit_transform(all_categories)\n",
    "\n",
    "# verfiy that the number of rows matches the number of rows in `books_df`\n",
    "# verify that the number of columns matches the number of unique categories\n",
    "targets.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
