{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualization \n",
    "\n",
    "In this notebook I use Decision Trees to identify underlying patterns in our book data that our stakeholders can use to impact their businesses.\n",
    "\n",
    "\n",
    "By: Prince Okpoziakpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3287, 21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the book data into the 'books_df' dataframe\n",
    "books_df = pd.read_csv('../data/final_books.csv')\n",
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'isbn', 'page_count', 'publishing_date', 'form',\n",
       "       'publisher', 'language', 'author', 'illustrator',\n",
       "       'originally_published', 'genres', 'subject', 'awards', 'nominations',\n",
       "       'characters', 'description', 'sub_title', 'book_id', 'average_rating',\n",
       "       'ratings_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3144, 21)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the books that have a description\n",
    "books_df = books_df.loc[~books_df.description.isna()] \n",
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3144 entries, 0 to 3286\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    3144 non-null   object \n",
      " 1   title                 3144 non-null   object \n",
      " 2   isbn                  2883 non-null   object \n",
      " 3   page_count            3107 non-null   object \n",
      " 4   publishing_date       3143 non-null   object \n",
      " 5   form                  3019 non-null   object \n",
      " 6   publisher             3144 non-null   object \n",
      " 7   language              3143 non-null   object \n",
      " 8   author                3043 non-null   object \n",
      " 9   illustrator           315 non-null    object \n",
      " 10  originally_published  2862 non-null   object \n",
      " 11  genres                1773 non-null   object \n",
      " 12  subject               2998 non-null   object \n",
      " 13  awards                278 non-null    object \n",
      " 14  nominations           379 non-null    object \n",
      " 15  characters            387 non-null    object \n",
      " 16  description           3144 non-null   object \n",
      " 17  sub_title             1248 non-null   object \n",
      " 18  book_id               3144 non-null   object \n",
      " 19  average_rating        159 non-null    float64\n",
      " 20  ratings_count         159 non-null    float64\n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 540.4+ KB\n"
     ]
    }
   ],
   "source": [
    "books_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773, 21)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the books that have categories\n",
    "books_df = books_df.loc[~books_df.genres.isna()]\n",
    "books_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graphic novel, Comics, Fiction                                1\n",
       "Thriller, Spy fiction, Suspense, Adventure fiction            1\n",
       "Young adult fiction, Adventure fiction                        1\n",
       "Novel, Science fiction, Fantasy Fiction, Dystopian Fiction    1\n",
       "Fiction, Children's literature, Christmas Story               1\n",
       "                                                             ..\n",
       "Novel, Fiction, Chick lit, Humor, Roman à clef                1\n",
       "Novel, Humor, Mystery, Crime fiction                          1\n",
       "Fairy tale, Fiction                                           1\n",
       "Novel, Creative nonfiction, Road Fiction                      1\n",
       "Novel, Adventure fiction, Nautical fiction                    1\n",
       "Name: genres, Length: 783, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = books_df.genres.value_counts()\n",
    "category_counts[category_counts == 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize each document from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the vectorizer and transforming the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 21927\n",
      "Sample features: ['amüsiert' 'ana' 'anagrammatic' 'anahuac' 'anais']\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] \n",
      "\n",
      "(1773, 21927)\n"
     ]
    }
   ],
   "source": [
    "# instantiate the CountVectorizer object; `stop_words` parameter makes sure \n",
    "# we exclude English stop words\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# extract the 'description' column and convert it into an array \n",
    "descriptions = books_df.description.to_numpy()\n",
    "\n",
    "# fit the vectorizer and transform the corpus\n",
    "bag_of_words = vectorizer.fit_transform(descriptions)\n",
    "\n",
    "print(f\"Vocabulary size: {vectorizer.vocabulary_.__len__()}\")\n",
    "print(f\"Sample features: {vectorizer.get_feature_names_out()[1000:1005]}\\n\")\n",
    "print(bag_of_words.toarray(), '\\n')\n",
    "\n",
    "print(bag_of_words.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the categories of each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories:  312\n"
     ]
    }
   ],
   "source": [
    "# determine the number of unique categories that exist in the dataset\n",
    "all_categories = [] \n",
    "for categories_list_string in books_df.genres: \n",
    "    if type(categories_list_string) == str:\n",
    "        c = categories_list_string.\\\n",
    "        rstrip().\\\n",
    "        lstrip().\\\n",
    "        replace('[', '').\\\n",
    "        replace(']', '').\\\n",
    "        replace(\"\\'\", '').\\\n",
    "        replace(\"\\\"\", '').\\\n",
    "        split(',')\n",
    "        all_categories += c\n",
    "\n",
    "print(\"Number of unique categories: \", len(set(all_categories)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and transform the targets into a label indicator matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'main_categories'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w2/c53crljd2y523fsqplb9bml00000gp/T/ipykernel_44820/2774454656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert the type of the categories from string into an array of categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m all_categories = books_df.main_categories.apply(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'main_categories'"
     ]
    }
   ],
   "source": [
    "# convert the type of the categories from string into an array of categories\n",
    "all_categories = books_df.main_categories.apply(\n",
    "    lambda s: s.\\\n",
    "        rstrip().\\\n",
    "        lstrip().\\\n",
    "        replace('[', '').\\\n",
    "        replace(']', '').\\\n",
    "        replace(\"\\'\", '').\\\n",
    "        replace(\"\\\"\", '').\\\n",
    "        split(',')\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the binarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# fit and transform the labels of the targets into a label indicator matrix\n",
    "targets = mlb.fit_transform(all_categories)\n",
    "\n",
    "# verfiy that the number of rows matches the number of rows in `books_df`\n",
    "# verify that the number of columns matches the number of unique categories\n",
    "targets.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = tts(bag_of_words, targets, random_state=42, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X_test, y_test, cv=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_depth()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
